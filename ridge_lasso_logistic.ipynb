{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "**Regularization** is the process of adding information in order to solve an ill-posed problem or to prevent overfitting.\n",
    "\n",
    "![alt-текст](images/overfitting.png)\n",
    "![alt-текст](images/overfitting_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression\n",
    "\n",
    "While ordinary least squares regression is a good way to fit a linear model onto a dataset, it relies on the fact that the dataset's features are each independent, i.e. uncorrelated. When many of the dataset features are linearly correlated, e.g. if a dataset has multiple features depicting the same price in different currencies, it makes the least squares regression model highly sensitive to noise in the data.\n",
    "\n",
    "Because real life data tends to have noise, and will often have some linearly correlated features in the dataset, we combat this by performing regularization.\n",
    "\n",
    "For ordinary least squares regression, the goal is to find the weights (coefficients) for the linear model that minimize the sum of squared residuals:\n",
    "\n",
    "$$\n",
    "    \\sum\\limits_{i=1}^{n} (x_iw - y_i)^2\n",
    "$$\n",
    "\n",
    "where each xi represents a data observation and yi is the corresponding label.\n",
    "\n",
    "For regularization, the goal is to not only minimize the sum of squared residuals, but to do this with coefficients as small as possible. The smaller the coefficients, the less susceptible they are to random noise in the data. The most commonly used form of regularization is ridge regularization.\n",
    "\n",
    "With ridge regularization, the goal is now to find the weights that minimize the following quantity:\n",
    "\n",
    "$$\n",
    "    \\alpha \\Vert w \\Vert^2_2 + \\sum\\limits_{i=1}^{n} (x_iw - y_i)^2\n",
    "$$\n",
    "\n",
    "where α is a non-negative real number hyperparameter and ||w||2 represents the L2 norm of the weights. \n",
    "\n",
    "![alt-текст](images/ridge_vs_ols.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7406426641094095\n",
      "[-1.08011358e-01  4.64204584e-02  2.05586264e-02  2.68673382e+00\n",
      " -1.77666112e+01  3.80986521e+00  6.92224640e-04 -1.47556685e+00\n",
      "  3.06049479e-01 -1.23345939e-02 -9.52747232e-01  9.31168327e-03\n",
      " -5.24758378e-01]\n"
     ]
    }
   ],
   "source": [
    "# OLS\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X, y)\n",
    "print(reg.score(X, y))\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7406002922228037\n",
      "[-1.07473720e-01  4.65716366e-02  1.59989982e-02  2.67001859e+00\n",
      " -1.66846452e+01  3.81823322e+00 -2.69060598e-04 -1.45962557e+00\n",
      "  3.03515266e-01 -1.24205910e-02 -9.40758541e-01  9.36807461e-03\n",
      " -5.25966203e-01]\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "reg = linear_model.Ridge(alpha=0.1)\n",
    "reg.fit(X, y)\n",
    "print(reg.score(X, y))\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regression\n",
    "\n",
    "Only difference between Ridge and Lasso:\n",
    "$$\n",
    "    \\alpha \\Vert w \\Vert^2_1 + \\sum\\limits_{i=1}^{n} (x_iw - y_i)^2\n",
    "$$\n",
    "\n",
    "LASSO regularization tends to prefer linear models with fewer parameter values. This means that it will likely zero-out some of the weight coefficients. This reduces the number of features that the model is actually dependent on (since some of the coefficients will now be 0), which can be beneficial when some features are completely irrelevant or duplicates of other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7269834862602695\n",
      "[-0.09789363  0.04921111 -0.03661906  0.95519003 -0.          3.70320175\n",
      " -0.01003698 -1.16053834  0.27470721 -0.01457017 -0.77065434  0.01024917\n",
      " -0.56876914]\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "reg = linear_model.Lasso(alpha=0.1)\n",
    "reg.fit(X, y)\n",
    "print(reg.score(X, y))\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc. Each object being detected in the image would be assigned a probability between 0 and 1 and the sum adding to one.\n",
    "\n",
    "![alt-текст](images/log_reg.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Logistic function aka sigmoid\n",
    "def logistic(x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets look at it\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.linspace(-6, 6, 1000)\n",
    "y = [logistic(x) for x in X]\n",
    "\n",
    "plt.plot(X, y, label='Sigmoid')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('logistic(X)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model we will predict, described as:\n",
    "$$\n",
    "    y_i = f(x_i, \\beta) + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "In case of OLS we minimize residual sum of squares (RSS):\n",
    "$$\n",
    "    \\varepsilon_i^2 = \\sum\\limits_{i=1}^{n} (y_i - f(x_i, \\beta))^2\n",
    "$$\n",
    "\n",
    "Here we will do the same procedure using gradient descent method.\n",
    "![alt-текст](images/grad_desc.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our model, given beta y_i equals 1 with p = f(x_i, beta) and 0 with q = 1 - f(x_i, beta)\n",
    "\n",
    "So we can write down the probability density function:\n",
    "\n",
    "$$\n",
    "    p(y_i \\ | \\ x_i, \\beta) = f(x_i, \\beta)^{y_i} \\ (1 - f(x_i, \\beta))^{1-y_i}\n",
    "$$\n",
    "\n",
    "We usually call **p** as likelihood.\n",
    "\n",
    "$$\n",
    "    L(y_i \\ | \\ x_i, \\beta) = p(y_i \\ | \\ x_i, \\beta)\n",
    "$$\n",
    "\n",
    "It is simpler to maximize not the likelihood itself but the logarithm of likelihood because of logarithm features.\n",
    "\n",
    "$$\n",
    "    lnL(y_i \\ | \\ x_i, \\beta) = y_i ln(f(x_i, \\beta)) + (1 - y_i) ln(1 - f(x_i, \\beta))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_log_likelihood_i(x_i, y_i, beta):\n",
    "    # x_i - observation (i.e. vector with values for each feature)\n",
    "    if y_i == 1:\n",
    "        return np.log(logistic(np.dot(x_i, beta)))\n",
    "    else:\n",
    "        return np.log(1 - logistic(np.dot(x_i, beta)))\n",
    "    \n",
    "def logistic_log_likelihood(x, y, beta):\n",
    "    # x - the whole input\n",
    "    return sum(logistic_log_likelihood_i(x_i, y_i, beta)\n",
    "               for x_i, y_i in zip(x, y))\n",
    "\n",
    "def logistic_log_partial_ij(x_i, y_i, beta, j):\n",
    "    return (y_i - logistic(np.dot(x_i, beta))) * x_i[j]\n",
    "\n",
    "def logistic_log_gradient_i(x_i, y_i, beta):\n",
    "    return np.array([logistic_log_partial_ij(x_i, y_i, beta, j) for j, _ in enumerate(beta)])\n",
    "\n",
    "def logistic_log_gradient(x, y, beta):\n",
    "    all_gradients = np.array([logistic_log_gradient_i(x_i, y_i, beta) for x_i, y_i in zip(x, y)])\n",
    "    return np.sum(all_gradients, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some stuff for gradient descent\n",
    "\n",
    "def step(v, direction, step_size):\n",
    "#     print(type(v), v)\n",
    "#     print(type(direction), direction)\n",
    "    return v + step_size * direction\n",
    "\n",
    "def minimize_batch(fn, gradient_fn, beta_0, tolerance=0.01):\n",
    "    step_size = 0.1\n",
    "    beta = beta_0\n",
    "    value = fn(beta)\n",
    "    \n",
    "    while True:\n",
    "        gradient = gradient_fn(beta)\n",
    "        next_beta = step(beta, gradient, -step_size)\n",
    "        next_value = fn(next_beta)\n",
    "        \n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return beta\n",
    "        else:\n",
    "            beta, value = next_beta, next_value\n",
    "            \n",
    "def negate(f):\n",
    "    return lambda *args, **kwargs: -f(*args, **kwargs)\n",
    "\n",
    "def maximize_batch(fn, gradient_fn, beta_0, tolerance=0.0001):\n",
    "    return minimize_batch(negate(fn), negate(gradient_fn), beta_0, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.array([\n",
    "  [1, 0],\n",
    "  [1, 1],\n",
    "  [1, 2.2],\n",
    "  [1, 3.9],\n",
    "  [1, 4.1],\n",
    "  [1, 5.3],\n",
    "  [1, 7.0],\n",
    "  [1, 8]])\n",
    "\n",
    "labels = np.array(\n",
    "  [0, 0, 0, 0, 1, 1, 1, 1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# We need to maximize log likelihood\n",
    "fn = partial(logistic_log_likelihood, X_train, y_train)\n",
    "gradient_fn = partial(logistic_log_gradient, X_train, y_train)\n",
    "\n",
    "beta_0 = np.random.rand(2)\n",
    "\n",
    "beta_hat = maximize_batch(fn, gradient_fn, beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.8614562 ,  2.22157877])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014172841043042327"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(np.dot(beta_hat, np.array([1, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999865144782208"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(np.dot(beta_hat, np.array([1, 8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(test_labels, predicted_labels):\n",
    "    return np.sum([(pl - tl) ** 2 for pl, tl in zip(predicted_labels, test_labels)]) / len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013271132434006946"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([logistic(np.dot(beta_hat, np.array(x))) for x in X_test])\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
